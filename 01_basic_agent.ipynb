{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ac9e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import html\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d347f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "def get_wikipedia_summary(query: str) -> str:\n",
    "    \"\"\" this function is used to get the wikipedia summary of the query\"\"\"\n",
    "    response = httpx.get(\n",
    "        \"https://en.wikipedia.org/w/api.php\",\n",
    "        params={\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"list\": \"search\",\n",
    "            \"srsearch\": query\n",
    "        },\n",
    "        headers={\n",
    "            \"User-Agent\": \"KhushilApp/1.0 (https://example.com/contact)\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response.raise_for_status()\n",
    "    text = \"\"\n",
    "    for index,search in enumerate(response.json()['query']['search']):\n",
    "        raw_snippet = search['snippet']\n",
    "        cleaned_snippet = re.sub(r'<[^>]+>', '', raw_snippet)\n",
    "        text += f\"Search result {index+1}: {html.unescape(cleaned_snippet)}\\n\"\n",
    "    return text\n",
    "    \n",
    "\n",
    "# print(get_wikipedia_summary(\"AI agents\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4581371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def math_calculator(query:str)->str:\n",
    "    \"\"\" this function is used to calculate the result of the query\"\"\"\n",
    "    try:\n",
    "        result = eval(query)\n",
    "        return f\"The result of {query} is {result}\"\n",
    "    except Exception as e:\n",
    "        print(\"error -->\",e)\n",
    "        return f\"Invalid input: `{query}` can not be calculated\"\n",
    "\n",
    "# print(math_calculator(\"1+2/5%6-5\"))\n",
    "# print(math_calculator(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "034ab36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_todos() -> str:\n",
    "    \"\"\" this function is used to fetch the todos from the json placeholder\"\"\"\n",
    "    try:\n",
    "        response = httpx.get(\"https://jsonplaceholder.typicode.com/todos\")\n",
    "        if response.status_code != 200:\n",
    "            return \"Failed to fetch todos\"\n",
    "        todos = response.json()\n",
    "        return f\"Here are the todos: {todos}\"\n",
    "    except Exception as e:\n",
    "        print(\"error -->\", e)\n",
    "        return \"Failed to fetch todos\"\n",
    "\n",
    "# print(fetch_todos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95066a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "class Chat:\n",
    "    def __init__(self,system_prompt:str , model:str=\"gpt-oss:20b-cloud\"):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "        self.chat = ChatOllama(model=self.model)\n",
    "        \n",
    "        if system_prompt:\n",
    "            self.messages.append(SystemMessage(content=system_prompt))\n",
    "            self.chat.invoke([SystemMessage(content=system_prompt)])\n",
    "            \n",
    "    def __call__(self,message:str)->str:\n",
    "        self.messages.append(HumanMessage(content=message))\n",
    "        response = self.chat.invoke(self.messages)\n",
    "        self.messages.append(response)\n",
    "        return response.content\n",
    "    \n",
    "    def show_messages(self)->str:\n",
    "        return \"\\n\".join([m.content for m in self.messages])\n",
    "    \n",
    "    def __str__(self)->str:\n",
    "        return f\" Chat with {self.model} model\"\n",
    "    \n",
    "Ai_Chat = Chat(system_prompt=\"You are a helpful assistant\",model=\"qwen3-vl:235b-instruct-cloud\")\n",
    "print(Ai_Chat(\"What is the capital of India?\"))\n",
    "print(Ai_Chat(\"Explain me AI agents in short\"))\n",
    "Ai_Chat.show_messages()\n",
    "print(Ai_Chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ae5214cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "def get_message_role(message):\n",
    "    if type(message) == SystemMessage:\n",
    "        return \"System\"\n",
    "    elif type(message) == AIMessage:\n",
    "        return \"AI\"\n",
    "    elif type(message) == HumanMessage:\n",
    "        return \"User\"\n",
    "    elif type(message) == ToolMessage:\n",
    "        return \"Tool\"\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model: str = \"gpt-oss:20b-cloud\"):\n",
    "        self.model = model\n",
    "        self.system_prompt = \"\"\"\n",
    "        You are a helpful assistant that can use the following tools:\n",
    "        - get_wikipedia_summary , AFTER TOOL CALL WHEN YOU GET THE RESULT FROM THE TOOL, rephrase the final result to the user in a concise manner\n",
    "        - math_calculator , AFTER TOOL CALL WHEN YOU GET THE RESULT FROM THE TOOL ,after you get the result from the tool, you should return the result with calculation steps if possible to the user\n",
    "        - fetch_todos , AFTER TOOL CALL WHEN YOU GET THE RESULT FROM THE TOOL ,format properly the todos to the user\n",
    "        \"\"\"\n",
    "        self.messages = [SystemMessage(content=self.system_prompt)]\n",
    "        # Create a tool mapping for easier access\n",
    "        self.tools = {\n",
    "            \"get_wikipedia_summary\": get_wikipedia_summary,\n",
    "            \"math_calculator\": math_calculator,\n",
    "            \"fetch_todos\": fetch_todos,\n",
    "        }\n",
    "        self.chat = ChatOllama(model=self.model).bind_tools(\n",
    "            [get_wikipedia_summary, math_calculator, fetch_todos]\n",
    "        )\n",
    "\n",
    "    def __call__(self, message: str) -> str:\n",
    "        \n",
    "        self.messages.append(HumanMessage(content=message))\n",
    "        while True:\n",
    "            response = self.chat.invoke(self.messages)\n",
    "            self.messages.append(response)\n",
    "            # Execute all tool calls\n",
    "            if response.tool_calls:\n",
    "                tool_name = response.tool_calls[0][\"name\"]\n",
    "                tool_args = response.tool_calls[0][\"args\"]\n",
    "                tool_call_id = response.tool_calls[0][\"id\"]\n",
    "\n",
    "                print(f\"Calling tool: {tool_name} with args: {tool_args}\")\n",
    "\n",
    "                # Get the tool function and call it\n",
    "                tool_func = self.tools[tool_name]\n",
    "\n",
    "                # Handle tools with different signatures\n",
    "                if tool_name == \"fetch_todos\":\n",
    "                    result = tool_func()\n",
    "                else:\n",
    "                    result = tool_func(**tool_args)\n",
    "\n",
    "                # Append ToolMessage with tool_call_id (IMPORTANT!)\n",
    "                self.messages.append(\n",
    "                    ToolMessage(content=str(result), tool_call_id=tool_call_id)\n",
    "                )\n",
    "            else:\n",
    "                break \n",
    "            \n",
    "        \n",
    "        # Get the next response from the model\n",
    "        response = self.chat.invoke(self.messages)\n",
    "\n",
    "        # Append final response and return\n",
    "        self.messages.append(response)\n",
    "            \n",
    "        for m in self.messages:\n",
    "            if type(m) != ToolMessage and m.content != \"\":\n",
    "                print(f\"{get_message_role(m)}: {m.content}\", end=\"\\n\")\n",
    "        return response.content\n",
    "\n",
    "    def show_messages(self) -> str:\n",
    "        return [{m.content} for m in self.messages]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"Agent with {self.model} model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "67cf8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ccf0d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool: math_calculator with args: {'query': '2 + 6 / 7 + 90 % 50'}\n",
      "Calling tool: get_wikipedia_summary with args: {'query': 'AI agents'}\n",
      "Calling tool: fetch_todos with args: {}\n",
      "System: \n",
      "        You are a helpful assistant that can use the following tools:\n",
      "        - get_wikipedia_summary , AFTER TOOL CALL WHEN YOU GET THE RESULT FROM THE TOOL, rephrase the final result to the user in a concise manner\n",
      "        - math_calculator , AFTER TOOL CALL WHEN YOU GET THE RESULT FROM THE TOOL ,after you get the result from the tool, you should return the result with calculation steps if possible to the user\n",
      "        - fetch_todos , AFTER TOOL CALL WHEN YOU GET THE RESULT FROM THE TOOL ,format properly the todos to the user\n",
      "        \n",
      "User: whats 2 + 6 / 7 +90 % 50 and then also give me summary on AI agents and then fetch all todos for me\n",
      "AI: **1. Math result**\n",
      "\n",
      "\\(2 + \\dfrac{6}{7} + (90 \\bmod 50)\\)\n",
      "\n",
      "1. \\(6 \\div 7 = 0.857142857\\)\n",
      "2. \\(90 \\bmod 50 = 40\\)\n",
      "3. \\(2 + 0.857142857 + 40 = 42.857142857\\)\n",
      "\n",
      "**Answer:** 42.857142857 (≈ 42.86)\n",
      "\n",
      "---\n",
      "\n",
      "**2. Summary on AI agents**\n",
      "\n",
      "AI agents are autonomous software entities that perceive their environment, reason about it, and take action to achieve specified goals. Modern AI agents combine machine‑learning models (e.g., language models, vision models) with planning and decision‑making modules. They can:\n",
      "\n",
      "* **Perceive** through sensors or data streams (text, images, internal state).\n",
      "* **Plan** by generating possible action sequences, often using reinforcement‑learning or symbolic planners.\n",
      "* **Act** by invoking APIs, editing documents, controlling robots, or interacting with users.\n",
      "* **Learn** from experience, continuously improving performance.\n",
      "\n",
      "Common use‑cases include virtual assistants, autonomous vehicles, smart‑home controllers, and chatbot/assistant agents for business workflows. Recent advances focus on modular, reusable “agent kits” that let developers compose complex behaviours from base models and domain‑specific skills.\n",
      "\n",
      "---\n",
      "\n",
      "**3. Todos (formatted)**  \n",
      "\n",
      "Below is a concise table showing the first 10 todos.  \n",
      "The full list contains 200 items (IDs 1‑200). Let me know if you’d like to see a different slice or aggregated stats.\n",
      "\n",
      "| ID | Title | Completed |\n",
      "|----|-------|-----------|\n",
      "| 1  | delectus aut autem | No |\n",
      "| 2  | quis ut nam facilis et officia qui | No |\n",
      "| 3  | fugiat veniam minus | No |\n",
      "| 4  | et porro tempora | Yes |\n",
      "| 5  | laboriosam mollitia et enim quasi adipisci quia provident illum | No |\n",
      "| 6  | qui ullam ratione quibusdam voluptatem quia omnis | No |\n",
      "| 7  | illo expedita consequatur quia in | No |\n",
      "| 8  | quo adipisci enim quam ut ab | Yes |\n",
      "| 9  | molestias perspiciatis ipsa | No |\n",
      "| 10 | illo est ratione doloremque quia maiores aut | Yes |\n",
      "\n",
      "*All 200 todos are available in the dataset you requested.*\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_agent(\"whats 2 + 6 / 7 +90 % 50 and then also give me summary on AI agents and then fetch all todos for me\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57edb367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent with gpt-oss:20b-cloud model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'\\n        You are a helpful assistant that can use the following tools:\\n        - get_wikipedia_summary\\n        - math_calculator\\n        - fetch_todos\\n        '}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ai_agent)\n",
    "ai_agent.show_messages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
